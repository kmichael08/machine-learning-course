{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and cross-validation \n",
    "\n",
    "In this exercise you will implement a validation pipeline. \n",
    "\n",
    "At the end of Exercise 2, you tested your model against the training and test datasets. As you should observe, there's a gap between the results. By validating your model, not only should you be able to anticipate the test time performance, but also have a method to compare different models.\n",
    "\n",
    "Implement the basic validation method, i.e. a random split. Test it with your model from Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-11-06 19:07:18--  https://www.dropbox.com/s/zey0gx91pna8irj/mieszkania.csv?dl=1\n",
      "Translacja www.dropbox.com (www.dropbox.com)... 162.125.66.1, 2620:100:6022:1::a27d:4201\n",
      "Łączenie się z www.dropbox.com (www.dropbox.com)|162.125.66.1|:443... połączono.\n",
      "Żądanie HTTP wysłano, oczekiwanie na odpowiedź... 302 Found\n",
      "Lokalizacja: https://dl.dropboxusercontent.com/content_link/f7SJbHhRRHDSDw0F8tgnMGwRlQ46sy7ZPtS3dPVJwtjkFVgnJLzIypa6H98B9l2V/file?dl=1 [podążanie]\n",
      "--2017-11-06 19:07:19--  https://dl.dropboxusercontent.com/content_link/f7SJbHhRRHDSDw0F8tgnMGwRlQ46sy7ZPtS3dPVJwtjkFVgnJLzIypa6H98B9l2V/file?dl=1\n",
      "Translacja dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.66.6, 2620:100:6022:6::a27d:4206\n",
      "Łączenie się z dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.66.6|:443... połączono.\n",
      "Żądanie HTTP wysłano, oczekiwanie na odpowiedź... 200 OK\n",
      "Długość: 6211 (6,1K) [application/binary]\n",
      "Zapis do: `mieszkania.csv'\n",
      "\n",
      "mieszkania.csv      100%[===================>]   6,07K  --.-KB/s    in 0s      \n",
      "\n",
      "2017-11-06 19:07:21 (612 MB/s) - zapisano `mieszkania.csv' [6211/6211]\n",
      "\n",
      "--2017-11-06 19:07:21--  https://www.dropbox.com/s/dbrj6sbxb4ayqjz/mieszkania_test.csv?dl=1\n",
      "Translacja www.dropbox.com (www.dropbox.com)... 162.125.66.1, 2620:100:6022:1::a27d:4201\n",
      "Łączenie się z www.dropbox.com (www.dropbox.com)|162.125.66.1|:443... połączono.\n",
      "Żądanie HTTP wysłano, oczekiwanie na odpowiedź... 302 Found\n",
      "Lokalizacja: https://dl.dropboxusercontent.com/content_link/pqtUu0fDSQvYWdK2PRF0mxPyb4jKaj49G1uUJ623FC16Jrkov9TOKaj7Dcw8EKGs/file?dl=1 [podążanie]\n",
      "--2017-11-06 19:07:22--  https://dl.dropboxusercontent.com/content_link/pqtUu0fDSQvYWdK2PRF0mxPyb4jKaj49G1uUJ623FC16Jrkov9TOKaj7Dcw8EKGs/file?dl=1\n",
      "Translacja dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.66.6, 2620:100:6022:6::a27d:4206\n",
      "Łączenie się z dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.66.6|:443... połączono.\n",
      "Żądanie HTTP wysłano, oczekiwanie na odpowiedź... 200 OK\n",
      "Długość: 6247 (6,1K) [application/binary]\n",
      "Zapis do: `mieszkania_test.csv'\n",
      "\n",
      "mieszkania_test.csv 100%[===================>]   6,10K  --.-KB/s    in 0s      \n",
      "\n",
      "2017-11-06 19:07:22 (773 MB/s) - zapisano `mieszkania_test.csv' [6247/6247]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "!wget -O mieszkania.csv https://www.dropbox.com/s/zey0gx91pna8irj/mieszkania.csv?dl=1\n",
    "!wget -O mieszkania_test.csv https://www.dropbox.com/s/dbrj6sbxb4ayqjz/mieszkania_test.csv?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> mieszkania.csv <==\r\n",
      "m2,dzielnica,ilość_sypialni,ilość_łazienek,rok_budowy,parking_podziemny,cena\r\n",
      "104,mokotowo,2,2,1940,1,780094\r\n",
      "43,ochotowo,1,1,1970,1,346912\r\n",
      "128,grodziskowo,3,2,1916,1,523466\r\n",
      "112,mokotowo,3,2,1920,1,830965\r\n",
      "149,mokotowo,3,3,1977,0,1090479\r\n",
      "80,ochotowo,2,2,1937,0,599060\r\n",
      "58,ochotowo,2,1,1922,0,463639\r\n",
      "23,ochotowo,1,1,1929,0,166785\r\n",
      "40,mokotowo,1,1,1973,0,318849\r\n",
      "\r\n",
      "==> mieszkania_test.csv <==\r\n",
      "m2,dzielnica,ilość_sypialni,ilość_łazienek,rok_budowy,parking_podziemny,cena\r\n",
      "71,wolowo,2,2,1912,1,322227\r\n",
      "45,mokotowo,1,1,1938,0,295878\r\n",
      "38,mokotowo,1,1,1999,1,306530\r\n",
      "70,ochotowo,2,2,1980,1,553641\r\n",
      "136,mokotowo,3,2,1939,1,985348\r\n",
      "128,wolowo,3,2,1983,1,695726\r\n",
      "23,grodziskowo,1,1,1975,0,99751\r\n",
      "117,mokotowo,3,2,1942,0,891261\r\n",
      "65,ochotowo,2,1,2002,1,536499\r\n"
     ]
    }
   ],
   "source": [
    "!head mieszkania.csv mieszkania_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    m2    dzielnica  ilość_sypialni  ilość_łazienek  rok_budowy  \\\n",
      "0  104     mokotowo               2               2        1940   \n",
      "1   43     ochotowo               1               1        1970   \n",
      "2  128  grodziskowo               3               2        1916   \n",
      "3  112     mokotowo               3               2        1920   \n",
      "4  149     mokotowo               3               3        1977   \n",
      "5   80     ochotowo               2               2        1937   \n",
      "6   58     ochotowo               2               1        1922   \n",
      "7   23     ochotowo               1               1        1929   \n",
      "8   40     mokotowo               1               1        1973   \n",
      "9  138     mokotowo               3               2        2011   \n",
      "\n",
      "   parking_podziemny     cena  \n",
      "0                  1   780094  \n",
      "1                  1   346912  \n",
      "2                  1   523466  \n",
      "3                  1   830965  \n",
      "4                  0  1090479  \n",
      "5                  0   599060  \n",
      "6                  0   463639  \n",
      "7                  0   166785  \n",
      "8                  0   318849  \n",
      "9                  0  1011395  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "def get_dataset(path):\n",
    "    with open(path) as flats:\n",
    "        data = pandas.read_csv(flats)\n",
    "    #data = data.sample(frac=1)\n",
    "    return data\n",
    "\n",
    "def get_training_dataset():\n",
    "    data_path = 'mieszkania.csv'\n",
    "    return get_dataset(data_path)\n",
    "\n",
    "def get_testing_dataset():\n",
    "    data_path = 'mieszkania_test.csv'\n",
    "    return get_dataset(data_path)\n",
    "\n",
    "def l2_loss(ys, ps):\n",
    "    \"\"\"\n",
    "    Least square error.\n",
    "    :param ys: ground truth prices\n",
    "    :param ps: prediction prices\n",
    "    \"\"\"\n",
    "    # quicker solution\n",
    "    # return np.linalg.norm(y - x) / len(ys)\n",
    "    return math.sqrt(sum((y - x) ** 2 for x, y in zip(ys, ps)) / len(ys))\n",
    "\n",
    "dataset = get_training_dataset()\n",
    "ys = dataset['cena']\n",
    "\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'ochotowo', 'wolowo', 'grodziskowo', 'mokotowo'})\n"
     ]
    }
   ],
   "source": [
    "def get_districts_set():\n",
    "    return frozenset(dataset['dzielnica'])\n",
    "\n",
    "districts = get_districts_set()\n",
    "\n",
    "print(districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/Pulpit/jnp_ml/mlenv/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features(data=dataset):\n",
    "    m2 = [item / 200 for item in data['m2']]\n",
    "    bedrooms = data['ilość_sypialni']\n",
    "    bathrooms = data['ilość_łazienek']\n",
    "    construction_year = [(2017 - year) / 100 for year in data['rok_budowy']]\n",
    "    parking_lot = data['parking_podziemny']\n",
    "    district_features = [np.array(np.array(data['dzielnica']) == np.array(district), dtype=float) for district in districts]\n",
    "\n",
    "    area_data = dataset.get(['m2', 'cena', 'dzielnica'])\n",
    "    area_data['cena'] /= area_data['m2']\n",
    "    average_district_prices_per_meter = area_data.groupby('dzielnica')['cena'].mean()\n",
    "\n",
    "    average_meter_price_feature = [area * average_district_prices_per_meter[district] for area, district in \n",
    "                                  zip(data['m2'], data['dzielnica'])]\n",
    "    average_meter_price_feature /= np.mean(average_meter_price_feature)\n",
    "\n",
    "    #features\n",
    "    xs = np.array([m2, bedrooms, bathrooms, construction_year, parking_lot] + district_features + \n",
    "                  [average_meter_price_feature]).T\n",
    "    return xs\n",
    "\n",
    "xs = get_features(dataset)\n",
    "\n",
    "print(xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989255862116 r2_score on training\n",
      "28160.77291537937 l2_loss on training\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "X = xs\n",
    "regr = LinearRegression()\n",
    "regr.fit(X, ys) # training\n",
    "\n",
    "print(regr.score(X, ys), 'r2_score on training')\n",
    "\n",
    "sk_loss = l2_loss(ys, regr.predict(X))\n",
    "print(sk_loss, 'l2_loss on training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923261962644 r2_score on testing\n",
      "80204.34508809487 l2_loss on testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/Pulpit/jnp_ml/mlenv/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "testing_data = get_testing_dataset()\n",
    "ys_testing = testing_data['cena']\n",
    "xs_testing = get_features(testing_data)\n",
    "\n",
    "print(regr.score(xs_testing, ys_testing), 'r2_score on testing')\n",
    "print(l2_loss(ys_testing, regr.predict(xs_testing)), 'l2_loss on testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the training data first. Our goal is to get better model, than the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134,) (66,)\n",
      "0.989313809756 r2_score on training\n",
      "27276.318362422906 l2_loss on training\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.33, random_state=42)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print(regr.score(X_train, y_train), 'r2_score on training')\n",
    "\n",
    "sk_loss = l2_loss(y_train, regr.predict(X_train))\n",
    "print(sk_loss, 'l2_loss on training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987828172863 r2_score on testing\n",
      "31190.588872936456 l2_loss on testing\n"
     ]
    }
   ],
   "source": [
    "print(regr.score(X_test, y_test), 'r2_score on testing')\n",
    "\n",
    "sk_loss = l2_loss(y_test, regr.predict(X_test))\n",
    "print(sk_loss, 'l2_loss on testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the random split validation reliable, a huge chunk of training data may be needed. To get over this problem, one may apply cross-validaiton.\n",
    "\n",
    "![alt-text](https://chrisjmccormick.files.wordpress.com/2013/07/10_fold_cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now implement the method. Make sure that:\n",
    "* number of partitions is a parameter,\n",
    "* the method is not limited to `mieszkania.csv`,\n",
    "* the method is not limited to one specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation is for model validation!!!\n",
    "https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation\n",
    "Compare with the result from scikit-learn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26599.8249846\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "\n",
    "def cross_validation(model, X, y, folds, loss_function):\n",
    "    \"\"\"\n",
    "    :param model: model object, that has the method fit, predict\n",
    "    :param X: training data\n",
    "    :param y: target values\n",
    "    :param folds: the number of folds (splits)\n",
    "    :param loss_function: loss function\n",
    "    :return: averged loss function score\n",
    "    \"\"\"\n",
    "    def single_result(x_subset, y_subset):\n",
    "        model.fit(x_subset, y_subset)\n",
    "        return loss_function(y_subset, model.predict(x_subset))\n",
    "    \n",
    "    x_splits = np.array_split(X, folds)\n",
    "    y_splits = np.array_split(y, folds)\n",
    "    \n",
    "    return np.average([single_result(x_sub, y_sub) for x_sub, y_sub in zip(x_splits, y_splits)])\n",
    "    \n",
    "    \n",
    "print(cross_validation(regr, xs, ys, folds=3, loss_function=l2_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that sometimes validation may be tricky, e.g. significant class imbalance, having a small number of subjects, geographically clustered instances...\n",
    "\n",
    "What could in theory go wrong here with random, unstratified partitions? Think about potential solutions and investigate the data in order to check whether these problems arise here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# TODO: Investigate the data #\n",
    "##############################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
